# import streamlit as st 
# from utils import print_messages 
# from langchain_core.messages import ChatMessage
# from langchain.chains import ConversationalRetrievalChain
# from langchain_core.output_parsers import StrOutputParser
# from langchain_core.chat_history import BaseChatMessageHistory 
# from langchain_core.runnables.history import RunnableWithMessageHistory
# from langchain_community.chat_message_histories import ChatMessageHistory
# from langchain_core.runnables import RunnablePassthrough
# import os 
# from gemini import llm_model
# from prompt import chat_prompt
# from dataloader import page_content 
# from embeddings import text_split , vector_store
# from retriever import retriever


# st.set_page_config(page_title = "ChatBot" , page_icon = "ğŸ—¨ï¸")
# st.title("ğŸ—¨ï¸ BookMark Chatbot") 

# os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]

# #session stateë¥¼ ì‚¬ìš©í•´ì„œ dataë¥¼ ê³„ì† ê¸°ë¡í•˜ëŠ” ì½”ë“œ (ìºì‹±)
# if "messages" not in st.session_state : #session stateì— messages ë¼ëŠ” key ê°’ì´ ì—†ìœ¼ë©´,
#     st.session_state['messages'] = [] #ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ìƒˆë¡œ ìƒì„± 

# if "store" not in st.session_state :
#     st.session_state["store"] = dict()
    
# with st.sidebar : 
#     session_id = st.text_input("Session ID" , value = "abc123") #ì¹´í†¡ë°© IDì™€ ê°™ì€ ê°œë…
#     #anthropic_api_key = st.text_input("Gemini API Key", key="file_qa_api_key", type="password")
#     clear_btn = st.button("ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™”") 
    
#     if clear_btn : 
#         st.session_state["message"]  = [] 
#         #st.seesion_state['store'] = dict() -> ì´ì „ ëŒ€í™” ê¸°ë¡ë“¤ë„ ëª¨ë‘ ì´ˆê¸°í™” í•˜ê³  ì‹¶ì„ ê²½ìš° 
#         st.experimental_rerun() #ìƒˆë¡œê³ ì¹¨
           
# #ì´ì „ ëŒ€í™”ê¸°ë¡ ì¶œë ¥ ì½”ë“œ 
# print_messages() 


# #ì„¸ì…˜IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ 
# def get_session_history(session_ids : str) -> BaseChatMessageHistory :
#     if session_ids not in st.session_state["store"] : #ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš° 
#         #ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥ 
#         st.session_state["store"][session_ids] = ChatMessageHistory() 
#     return st.session_state["store"][session_ids] #í•´ë‹¹ ì„¸ì…˜IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜


# if user_input := st.chat_input("ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.") :
#     #ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš© 
#     st.chat_message('user').write(f'{user_input}') #user message ì…ë ¥ -> ì…ë ¥ì„ í•˜ê²Œ ë˜ë©´ ìƒˆë¡œê³ ì¹¨ ëœë‹¤. (ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„í•˜ê¸°) 
#     #st.session_state['messages'].append(("user" , user_input))
#     st.session_state['messages'].append(ChatMessage(role = "user" , content=user_input)) #ì½”ë“œê°€ ì¡°ê¸ˆ ë” ëª…í™•í•¨.
    
#     #AIì˜ ë‹µë³€ 
#     with st.chat_message("assistant") :
        
#         api_key = 'AIzaSyCtUU0L03NUTda15zkyYbPTakuXt6k1Xjs'

#         if "GOOGLE_API_KEY" not in os.environ:
#             os.environ["GOOGLE_API_KEY"] = api_key
        
#         #1. ì‚¬ìš©ì url ë„£ê¸° 
#         urls = ["https://www.youtube.com/watch?v=ulMzXgPmPhY&list=RD_Ra1M4uYdTI&index=23",
#         "https://www.youtube.com/watch?v=cuHInDaF8WA"]
        
#         #2. content loader
#         docs = page_content(urls)
        
#         #3. split ë° embedding 
#         splits = text_split(docs)
        
#         #4.vector store
#         vectorstore = vector_store(splits)
        
#         #5.retreiver ì„¤ì • 
#         chat_rt = retriever( vectorstore = vectorstore)
        
#         #6.ëª¨ë¸ìƒì„± 
#         llm = llm_model()
#         #llm = ChatOpenAI(streaming = True , callbacks = [stream_handler]) 
        
#         #7.í”„ë¡¬í”„íŠ¸ ìƒì„± 
#         prompt = chat_prompt()
        
#         def format_docs(docs):
#         # ê²€ìƒ‰í•œ ë¬¸ì„œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ í•©ì³ì¤ë‹ˆë‹¤.
#             return "\n\n".join(doc.page_content for doc in docs)
        
#         #8. ì²´ì¸ìƒì„± 
#         rag_chain = (
#             {"context": chat_rt | format_docs , "question": RunnablePassthrough() }
#             | prompt
#             | llm
#             | StrOutputParser()
#         )   
    
#         # 9. ëŒ€í™”ê¸°ë¡ ì €ì¥ 
#         chain_with_memory = (
#             RunnableWithMessageHistory(         #RunnableWithMessageHistory ê°ì²´ ìƒì„± 
#                 rag_chain , #ì‹¤í–‰í•  Runnable ê°ì²´ 
#                 get_session_history, #ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
#                 input_messages_key="question", # ì‚¬ìš©ì ì§ˆë¬¸ì˜ í‚¤ 
#                 history_messages_key="history" # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤ 
#             )
#         )

#         response_stream = chain_with_memory.stream(
#                 #ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì…ë ¥
#                 {"question" : user_input} , 
#                 #ì„¸ì…˜ ID ì„¤ì • 
#                 config = {"configurable" : {"session_id" : session_id}})

#         # msg ="" 
#         # response_placeholder = st.empty()
        
#         # for chunk in response_stream :
#         #     msg += chunk.content
#         #     response_placeholder.markdown(msg)
        
#         #response = rag_chain.stream(user_input)
#         st.write(response_stream) #-> ì‹¤ì‹œê°„ìœ¼ë¡œ ì°íˆë¯€ë¡œ í•„ìš” X 
#         st.session_state['messages'].append(ChatMessage(role = "assistant" , content=response_stream))
